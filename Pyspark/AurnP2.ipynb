{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.appName('ArunP2').master('yarn').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**filter such that your RDD\\DF has products whose price is lesser than 100 USD \\\n",
    "on the filtered data set find out the higest value in the product_price column under each category \\\n",
    "on the filtered data set also find out total products under each category \\\n",
    "on the filtered data set also find out the average price of the product under each category \\\n",
    "on the filtered data set also find out the minimum price of the product under each category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders=spark.read.csv('/public/retail_db/products')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = spark.read.csv('/public/retail_db/products').toDF('product_id','prod_category_id','product_name','product_desc','product_price','product_image')\n",
    "\n",
    "products.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.createOrReplaceTempView('products')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#products whose price is lesser than 100 USD\n",
    "datasql=spark.sql('select * from products where product_price <100')\n",
    "datasql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#products whose price is lesser than 100 USD\n",
    "data = products.filter(products.product_price < 100)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set find out the higest value in the product_price column under each category\n",
    "datasql1 = spark.sql('select max(product_price) maximum, prod_category_id from products group by prod_category_id order by prod_category_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasql1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set find out the higest value in the product_price column under each category\n",
    "from pyspark.sql.types import IntegerType,FloatType\n",
    "from pyspark.sql.functions import *\n",
    "products = products.withColumn('product_id',products.product_id.cast(IntegerType())).withColumn('product_price',products.product_price.cast(FloatType()))\n",
    "products.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data1 = products.groupBy('prod_category_id').max('product_price').alias('max').orderBy('prod_category_id')\n",
    "data1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set also find out total products under each category\n",
    "datasql2= spark.sql('select count(product_id) total,prod_category_id from products group by prod_category_id order by prod_category_id')\n",
    "datasql2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set also find out total products under each category\n",
    "data2 = products.groupBy('prod_category_id').count().orderBy('prod_category_id')\n",
    "data2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set also find out the average price of the product under each category\n",
    "datasql3=spark.sql('select round(avg(product_price),2) avg,prod_category_id from products group by prod_category_id')\n",
    "datasql3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set also find out the average price of the product under each category\n",
    "data3 = products.groupBy('prod_category_id').agg(round(mean('product_price'),2).alias('avg')).orderBy('prod_category_id')\n",
    "data3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set also find out the minimum price of the product under each category\n",
    "datasql4 = spark.sql('select min(product_price) min,prod_category_id from products group by prod_category_id order by prod_category_id')\n",
    "datasql4.show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on the filtered data set also find out the minimum price of the product under each category\n",
    "data4 = products.groupBy('prod_category_id').min('product_price').alias('min').orderBy('prod_category_id')\n",
    "data4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.write.format('avro').save('/user/indirameduri/avro_Arun2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
