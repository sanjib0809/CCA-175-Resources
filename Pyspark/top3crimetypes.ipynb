{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data is available in HDFS file system under /public/crime/csv \\\n",
    "Structure of data (ID,Case Number,Date,Block,IUCR,Primary Type,Description,Location \\ Description,Arrest,Domestic,Beat,District,Ward,Community Area,FBI Code,X Coordinate,Y Coordinate,Year,Updated \\ On,Latitude,Longitude,Location) \\\n",
    "File format - text file \\\n",
    "Delimiter - “,” (use regex while splitting split(\",(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\", -1), as there are some fields \\ with comma and enclosed using double quotes. \\\n",
    "Get top 3 crime types based on number of incidents in RESIDENCE area using “Location Description” \\\n",
    "Store the result in HDFS path /user/<YOUR_USER_ID>/solutions/solution03/RESIDENCE_AREA_CRIMINAL_TYPE_DATA \\\n",
    "Output Fields: Crime Type, Number of Incidents \\\n",
    "Output File Format: JSON \\\n",
    "Output Delimiter: N/A \\\n",
    "Output Compression: No** \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('yarn').appName('parquet').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('/public/crime/csv/',header=True,inferSchema=True).toDF('ID','CaseNumber','Date','Block','IUCR','PrimaryType','Description','LocationDescription','Arrest','Domestic','Beat','District','Ward','CommunityArea','FBICode','XCoordinate','YCoordinate','Year','UpdatedOn','Latitude','Longitude','Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.registerTempTable('crime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.sql('select count(*),PrimaryType from crime where LocationDescription=\"RESIDENCE\" group by PrimaryType order by count(id) desc limit 3')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format('json').mode('overwrite').save('/user/indirameduri/solution03/RESIDENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''select PrimaryType,count(PrimaryType) over(partition by ) LocationDescription from (select PrimaryType,)\n",
    "            ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
